{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9575fd4c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-09T06:44:27.973601Z",
     "iopub.status.busy": "2024-07-09T06:44:27.973254Z",
     "iopub.status.idle": "2024-07-09T06:45:05.509063Z",
     "shell.execute_reply": "2024-07-09T06:45:05.507999Z"
    },
    "papermill": {
     "duration": 37.54375,
     "end_time": "2024-07-09T06:45:05.511389",
     "exception": false,
     "start_time": "2024-07-09T06:44:27.967639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.51 ðŸš€ Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Setup complete âœ… (4 CPUs, 31.4 GB RAM, 5689.3/8062.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "#-- Install ultralytics for YOLO World --------------------------------------------------------------------------\n",
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "#---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27de8e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:05.522381Z",
     "iopub.status.busy": "2024-07-09T06:45:05.521953Z",
     "iopub.status.idle": "2024-07-09T06:45:18.759847Z",
     "shell.execute_reply": "2024-07-09T06:45:18.758745Z"
    },
    "papermill": {
     "duration": 13.245784,
     "end_time": "2024-07-09T06:45:18.761961",
     "exception": false,
     "start_time": "2024-07-09T06:45:05.516177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Install deep-sort for obj tracking --------------------------------------------------------------------------\n",
    "\n",
    "!pip install deep-sort-realtime\n",
    "\n",
    "display.clear_output()\n",
    "#---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059bf433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:18.772527Z",
     "iopub.status.busy": "2024-07-09T06:45:18.772155Z",
     "iopub.status.idle": "2024-07-09T06:45:19.353581Z",
     "shell.execute_reply": "2024-07-09T06:45:19.352605Z"
    },
    "papermill": {
     "duration": 0.589503,
     "end_time": "2024-07-09T06:45:19.356000",
     "exception": false,
     "start_time": "2024-07-09T06:45:18.766497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Import -----------------------------------------------------------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "#---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb80cb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:19.365857Z",
     "iopub.status.busy": "2024-07-09T06:45:19.365561Z",
     "iopub.status.idle": "2024-07-09T06:45:19.372493Z",
     "shell.execute_reply": "2024-07-09T06:45:19.371529Z"
    },
    "papermill": {
     "duration": 0.014006,
     "end_time": "2024-07-09T06:45:19.374440",
     "exception": false,
     "start_time": "2024-07-09T06:45:19.360434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "#-- Initialize ---------------------------------------------------------------------------------------------------\n",
    "out_path = '/kaggle/working/'\n",
    "intput_path = '/kaggle/input/'\n",
    "\n",
    "lbls_file = intput_path + 'all-labels/all_labels.txt'\n",
    "\n",
    "drone_detector_weights_file = intput_path + 'drone-detection-yolov8-best-weights/best.pt'\n",
    "\n",
    "input_video_dir = intput_path + 'sample-videos-detecting-and-matching-objs-1/'\n",
    "result_video_dir = out_path + 'result_videos/'\n",
    "\n",
    "YOLO_Wordl_CONF_THRESHOLD = 0.25\n",
    "YOLO_Wordl_IOU_THRESHOLD = 0.5\n",
    "\n",
    "Drone_Detector_CONF_THRESHOLD = 0.25\n",
    "Drone_Detector_IOU_THRESHOLD = 0.5\n",
    "\n",
    "MOTION_THRESHOLD = 10\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:' , DEVICE)\n",
    "#---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7287de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:19.383888Z",
     "iopub.status.busy": "2024-07-09T06:45:19.383611Z",
     "iopub.status.idle": "2024-07-09T06:45:19.387721Z",
     "shell.execute_reply": "2024-07-09T06:45:19.386873Z"
    },
    "papermill": {
     "duration": 0.011024,
     "end_time": "2024-07-09T06:45:19.389669",
     "exception": false,
     "start_time": "2024-07-09T06:45:19.378645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Create Dir for saving Results ---------------------------------------------------------------------------------\n",
    "os.makedirs(result_video_dir, exist_ok=True)\n",
    "#-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0564a2f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:19.399206Z",
     "iopub.status.busy": "2024-07-09T06:45:19.398918Z",
     "iopub.status.idle": "2024-07-09T06:45:19.403241Z",
     "shell.execute_reply": "2024-07-09T06:45:19.402376Z"
    },
    "papermill": {
     "duration": 0.011261,
     "end_time": "2024-07-09T06:45:19.405138",
     "exception": false,
     "start_time": "2024-07-09T06:45:19.393877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- Set labels for ZSOD Models ------------------------------------------------------------------------------------\n",
    "all_labels = ['drone', 'UAV', 'Unmanned Aerial Vehicle', 'Quadcopter']\n",
    "# all_labels = ['person']            \n",
    "\n",
    "yolo_all_labels = all_labels\n",
    "#-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1192b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:19.414961Z",
     "iopub.status.busy": "2024-07-09T06:45:19.414671Z",
     "iopub.status.idle": "2024-07-09T06:45:47.405467Z",
     "shell.execute_reply": "2024-07-09T06:45:47.404498Z"
    },
    "papermill": {
     "duration": 27.998097,
     "end_time": "2024-07-09T06:45:47.407641",
     "exception": false,
     "start_time": "2024-07-09T06:45:19.409544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models loaded successfully :)\n"
     ]
    }
   ],
   "source": [
    "#-- Create and Initialize Models ----------------------------------------------------------------------------------\n",
    "#-- YOLO World --\n",
    "model_yolo_world_zsod = YOLO('yolov8x-worldv2.pt')\n",
    "model_yolo_world_zsod.set_classes(yolo_all_labels)\n",
    "\n",
    "\n",
    "#-- Custome Model for Drone Detection --\n",
    "model_drone_detector_yolov8 = YOLO(drone_detector_weights_file) \n",
    "\n",
    "#-- background subtractor --\n",
    "back_sub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=False)\n",
    "\n",
    "display.clear_output()\n",
    "print('All models loaded successfully :)')\n",
    "#-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52b164c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:47.417886Z",
     "iopub.status.busy": "2024-07-09T06:45:47.417492Z",
     "iopub.status.idle": "2024-07-09T06:45:47.424481Z",
     "shell.execute_reply": "2024-07-09T06:45:47.423642Z"
    },
    "papermill": {
     "duration": 0.014233,
     "end_time": "2024-07-09T06:45:47.426450",
     "exception": false,
     "start_time": "2024-07-09T06:45:47.412217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-- calculate IOU for 2 Deteced Objects --------------------------------------------------------------------------\n",
    "def calculate_iou(box1, box2):\n",
    "    \n",
    "    x1_1, y1_1, x2_1, y2_1 = box1\n",
    "    x1_2, y1_2, x2_2, y2_2 = box2\n",
    "    \n",
    "    x1_intersection = max(x1_1, x1_2)\n",
    "    y1_intersection = max(y1_1, y1_2)\n",
    "    x2_intersection = min(x2_1, x2_2)\n",
    "    y2_intersection = min(y2_1, y2_2)\n",
    "   \n",
    "    intersection_area = max(0, x2_intersection - x1_intersection + 1) * max(0, y2_intersection - y1_intersection + 1)    \n",
    "    box1_area = (x2_1 - x1_1 + 1) * (y2_1 - y1_1 + 1)\n",
    "    box2_area = (x2_2 - x1_2 + 1) * (y2_2 - y1_2 + 1)    \n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "#-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4803e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:45:47.436435Z",
     "iopub.status.busy": "2024-07-09T06:45:47.436143Z",
     "iopub.status.idle": "2024-07-09T06:46:16.950753Z",
     "shell.execute_reply": "2024-07-09T06:46:16.936356Z"
    },
    "papermill": {
     "duration": 29.526449,
     "end_time": "2024-07-09T06:46:16.957182",
     "exception": false,
     "start_time": "2024-07-09T06:45:47.430733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":)\n"
     ]
    }
   ],
   "source": [
    "#-- Run ------------------------------------------------------------------------------------------------------------------\n",
    "#-- Initialize DeepSort --\n",
    "tracker = DeepSort(max_age=30)\n",
    "\n",
    "#-- Load video file --\n",
    "video_path = '/kaggle/input/sample-videos-detecting-and-matching-objs-1/sample_video_drone (3).mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#-- Get video properties --\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "#-- Create video writer to save output video --\n",
    "out = cv2.VideoWriter('output_video_sample_video_drone (3).mp4', fourcc, fps, (width, height)) \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    #-- Detect Drone objects --\n",
    "    results = model_drone_detector_yolov8.predict(source=frame,\n",
    "                                                  conf=Drone_Detector_CONF_THRESHOLD,\n",
    "                                                  iou=Drone_Detector_IOU_THRESHOLD,\n",
    "                                                  show=False,\n",
    "                                                  save=False)\n",
    "    \n",
    "#     #-- Detect Person objects --\n",
    "#     results = model_yolo_world_zsod.predict(source=frame,\n",
    "#                                             conf=YOLO_Wordl_CONF_THRESHOLD,\n",
    "#                                             iou=YOLO_Wordl_IOU_THRESHOLD,\n",
    "#                                             show=False,\n",
    "#                                             save=False)\n",
    "\n",
    "            \n",
    "    #-- Extract bounding boxes and confidences --\n",
    "    detections = []\n",
    "    i = 0\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            bbox = box.xyxy[0].tolist()\n",
    "            conf = box.conf.tolist()[0]\n",
    "            detections.append((bbox, conf, 'drone'))  \n",
    "#             detections.append((bbox, conf, 'person'))  \n",
    "            \n",
    "            \n",
    "            bbox = [int(coord) for coord in bbox]\n",
    "            cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2)        \n",
    "            cv2.putText(frame, f'I: {i}', (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "    #-- Update tracker with detections --\n",
    "    tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "    #-- Draw bounding boxes for tracked objects --\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        bbox = [int(coord) for coord in ltrb]\n",
    "\n",
    "        #-- Draw bounding box --\n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'ID: {track_id}', (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    #-- Write frame to output video --\n",
    "    out.write(frame)\n",
    "\n",
    "#-- Release resources --\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "\n",
    "\n",
    "display.clear_output()\n",
    "print(':)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d1c18b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:46:16.988678Z",
     "iopub.status.busy": "2024-07-09T06:46:16.987721Z",
     "iopub.status.idle": "2024-07-09T06:46:17.036710Z",
     "shell.execute_reply": "2024-07-09T06:46:17.035389Z"
    },
    "papermill": {
     "duration": 0.070214,
     "end_time": "2024-07-09T06:46:17.039180",
     "exception": false,
     "start_time": "2024-07-09T06:46:16.968966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for video_file in os.listdir(input_video_dir):      \n",
    "    \n",
    "#     if 'human' not in video_file:\n",
    "#         continue\n",
    "        \n",
    "#     if video_file != 'sample_video_human (2).mp4':\n",
    "#         continue\n",
    "    \n",
    "\n",
    "#     #-- log --\n",
    "#     print(f'Processing {video_file} ==========================================================')\n",
    "    \n",
    "#     tracker = DeepSort(max_age=30, n_init=3)\n",
    "    \n",
    "#     #-- Create Folder for saving results --\n",
    "#     dot_index = video_file.rfind('.')   \n",
    "#     video_result_dir_name = 'result_for_' + video_file[:dot_index]\n",
    "#     video_result_dir_path = result_video_dir + video_result_dir_name + '/'\n",
    "#     os.makedirs(video_result_dir_path, exist_ok=True)\n",
    "        \n",
    "#     #-- load video --\n",
    "#     video_path = os.path.join(input_video_dir, video_file)    \n",
    "#     video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "#     #-- Get number of frames and fps -- \n",
    "#     number_of_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "#     print(f'number_of_frames: {number_of_frames}\\nfps: {fps}')\n",
    "    \n",
    "    \n",
    "\n",
    "#     #-- Get the width and height of the frames --\n",
    "#     frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "#     # Define the time interval t in seconds\n",
    "#     t = 2    \n",
    "#     frame_interval = t * fps\n",
    "    \n",
    "#     unique_objects_id = set()    \n",
    "#     unique_objects_tracks = dict()  \n",
    "#     time_obj = dict()\n",
    "#     track_obj = dict()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #-- Initialize VideoWriter to save the output video --\n",
    "#     result_video = cv2.VideoWriter(video_result_dir_path + video_file[:dot_index] + '.avi',\n",
    "#                                    cv2.VideoWriter_fourcc(*'XVID'),\n",
    "#                                    fps,\n",
    "#                                    (frame_width, frame_height))    \n",
    "    \n",
    "    \n",
    "#     #-- Run Object Detection Models Frame by Frame --\n",
    "#     frame_number = 0\n",
    "#     while video.isOpened():\n",
    "#         ret, frame = video.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "        \n",
    "#         main_frame = frame.copy()\n",
    "#         frame_number += 1   \n",
    "#         #-- log --\n",
    "#         print(f'\\tProcessing frame {frame_number} ------------------------------')       \n",
    "        \n",
    "        \n",
    "#         #-- Apply background subtraction --\n",
    "#         fg_mask = back_sub.apply(frame)        \n",
    "        \n",
    "#         #-- show some frames --\n",
    "#         if frame_number % frame_interval == 0:\n",
    "# #         if frame_number % (number_of_frames//5) == 0:\n",
    "#             plt.figure(figsize=(5, 5))\n",
    "#             plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "#             plt.axis('off')\n",
    "#             plt.title(f'main frame - frame number={frame_number}')\n",
    "#             file_name = f'main_frame_{frame_number}.png'\n",
    "#             plt.savefig(video_result_dir_path + file_name)\n",
    "#             plt.show()\n",
    "\n",
    "#             plt.figure(figsize=(5, 5))\n",
    "#             plt.imshow(cv2.cvtColor(fg_mask, cv2.COLOR_BGR2RGB))\n",
    "#             plt.axis('off')\n",
    "#             plt.title(f'fg_mask - frame number={frame_number}')\n",
    "#             file_name = f'fg_mask_{frame_number}.png'\n",
    "#             plt.savefig(video_result_dir_path + file_name)\n",
    "#             plt.show()\n",
    "        \n",
    "#         #-- Detect objects by YOLO-World --\n",
    "#         results_yolo_world_zsod = model_yolo_world_zsod.predict(source=frame,\n",
    "#                                                                 conf=YOLO_Wordl_CONF_THRESHOLD,\n",
    "#                                                                 iou=YOLO_Wordl_IOU_THRESHOLD,\n",
    "#                                                                 show=False,\n",
    "#                                                                 save=False)\n",
    "               \n",
    "        \n",
    "#         #-- Get only moving objects from results_yolo_world_zsod --\n",
    "#         n_all_objs_yolo_world_zsod = 0\n",
    "#         moving_objects_yolo_world_zsod = []        \n",
    "#         for result in results_yolo_world_zsod:\n",
    "#             for box in result.boxes:  \n",
    "#                 n_all_objs_yolo_world_zsod += 1\n",
    "                \n",
    "#                 class_id = int(box.cls)                 \n",
    "#                 label = yolo_all_labels[class_id]    \n",
    "#                 bbox = box.xyxy.tolist()[0]            \n",
    "#                 x1, y1, x2, y2 = map(int, bbox)                \n",
    "\n",
    "#                 #-- Check if the detected object has motion --\n",
    "#                 if fg_mask[y1:y2, x1:x2].mean() > MOTION_THRESHOLD:  \n",
    "#                     moving_objects_yolo_world_zsod.append((x1, y1, x2, y2, label))           \n",
    " \n",
    "            \n",
    "        \n",
    "#         #-- log --\n",
    "#         print(f' frame number: {frame_number} ------------------------------------------------------')\n",
    "#         print(f'all objs:\\tyolo_world:{n_all_objs_yolo_world_zsod}')\n",
    "#         print(f'moving objs:\\tyolo_world:{len(moving_objects_yolo_world_zsod)}')\n",
    "#         print('--------------------------------------------------------------------------')\n",
    "        \n",
    "#         moving_objects = moving_objects_yolo_world_zsod\n",
    "        \n",
    "#         detections = []              \n",
    "#         for (x1, y1, x2, y2, label) in moving_objects:\n",
    "#             w = int(x2 - x1)\n",
    "#             h = int(y2 - y1)\n",
    "#             x_center = int(x1 + w / 2)\n",
    "#             y_center = int(y1 + h / 2)\n",
    "            \n",
    "#             bbox = [x_center, y_center, w, h]          \n",
    "            \n",
    "#             score = 0.9\n",
    "#             detections.append(((bbox),score,label))    \n",
    "        \n",
    "#         t_ids = set()\n",
    "#         for obj in detections:\n",
    "#             tracker.update_tracks([obj], frame = main_frame)     \n",
    "            \n",
    "#             for track in tracker.tracker.tracks:   \n",
    "#                 if track.track_id not in t_ids:\n",
    "#                     t_ids.add(track.track_id)\n",
    "#                     track_obj[track.track_id] = obj\n",
    "            \n",
    "            \n",
    "        \n",
    "#         print(f' frame number: {frame_number} +++++++++++++++++++++++++++++++++++++++++++++')\n",
    "#         for t_id , obj in   track_obj.items():\n",
    "#             print(t_id, obj[2])\n",
    "#         print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        \n",
    "        \n",
    "#         tracks = tracker.update_tracks(detections, frame = main_frame)        \n",
    "\n",
    "#         # Collect unique object IDs\n",
    "#         n_tracks = 0\n",
    "#         ids = set()\n",
    "        \n",
    "#         for track in tracker.tracker.tracks:    \n",
    "#             n_tracks += 1\n",
    "#             ids.add(track.track_id)\n",
    "           \n",
    "#             unique_objects_id.add(track.track_id)\n",
    "#             if track.track_id not in unique_objects_tracks:\n",
    "#                 unique_objects_tracks[track.track_id] = track\n",
    "        \n",
    "#         print(f' frame number: {frame_number} +++++++++++++++++++++++++++++++++++++++++++++')\n",
    "#         print(f'detections: {len(detections)}')        \n",
    "#         print(f'n_tracks: {n_tracks}')   \n",
    "#         print(f'tracks:\\n {len(tracks)}')\n",
    "#         print(f'ids in this frame: {ids}')\n",
    "#         print(f'ids in interval: {unique_objects_id}')        \n",
    "#         print('++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "        \n",
    "        \n",
    "#         # If reached the frame interval, print unique objects and reset\n",
    "#         if frame_number % frame_interval == 0:\n",
    "#             print(f\"Unique objects in the last {t} seconds:\", len(unique_objects_id))\n",
    "# #             time_obj[frame_number / frame_interval] = unique_objects.copy()\n",
    "#             time_obj[frame_number / frame_interval] = unique_objects_tracks.copy()\n",
    "            \n",
    "#             unique_objects_id.clear()\n",
    "#             unique_objects_tracks = {}\n",
    "        \n",
    "        \n",
    "#         if frame_number % frame_interval == 0:\n",
    "            \n",
    "#             all_tracks = []        \n",
    "#             for track in tracker.tracker.tracks:    \n",
    "#                 if track.is_confirmed() and track.time_since_update == 0:\n",
    "#                     all_tracks.append(track)\n",
    "# #             for id,t in time_obj[frame_number / frame_interval].items():\n",
    "# #                 all_tracks.append(t)\n",
    "                \n",
    "# #             img = draw_boxes(frame.copy(), tracker.tracker.tracks)\n",
    "#             img = draw_boxes(frame.copy(), all_tracks)\n",
    "#             plt.figure(figsize=(10, 10))\n",
    "#             plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#             plt.axis('off')\n",
    "#             plt.title(f'tracking - frame number={frame_number}')\n",
    "# #             file_name = f'main_frame_{frame_number}.png'\n",
    "# #             plt.savefig(video_result_dir_path + file_name)\n",
    "#             plt.show()\n",
    "                \n",
    "                \n",
    "#         #-- plot bounding box for moving objects on the frame --\n",
    "#         for i, (x1, y1, x2, y2, label) in enumerate(moving_objects):            \n",
    "#             #-- crop detected object --\n",
    "#             cropped_object = main_frame[y1:y2, x1:x2]\n",
    "            \n",
    "#             #-- save croped object --\n",
    "#             if frame_number % (number_of_frames//5) == 0:\n",
    "#                 file_name = f'frame_{frame_number}_{i}_{label}.png'            \n",
    "#                 cv2.imwrite(video_result_dir_path + file_name, cropped_object)\n",
    "            \n",
    "#             #-- show cropped object --\n",
    "#             if frame_number % (number_of_frames//5) == 0:\n",
    "#                 plt.figure(figsize=(3, 3))\n",
    "#                 plt.imshow(cropped_object)\n",
    "#                 plt.axis('off')\n",
    "#                 plt.title(label)\n",
    "#                 plt.show\n",
    "            \n",
    "#             #-- plot bbox on the frame --\n",
    "#             color = (255, 0, 0)\n",
    "#             if 'yolov8' in label:\n",
    "#                 color = (255, 0, 0)\n",
    "#             elif 'yolo_world' in label:\n",
    "#                 color = (0, 255, 0)\n",
    "#             elif 'dino' in label:\n",
    "#                 color = (0, 0, 255)\n",
    "            \n",
    "                \n",
    "#             cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)  #-- Red box with thickness 2 --               \n",
    "#             cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "# #             print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "# #             print(x1,y1,x2,y2)\n",
    "# #             print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "            \n",
    "            \n",
    "            \n",
    "#         #-- Add frame to result video --\n",
    "#         result_video.write(frame)\n",
    "\n",
    "#         #-- show some frames --\n",
    "#         if frame_number % frame_interval == 0:\n",
    "# #         if frame_number % (number_of_frames//5) == 0:\n",
    "#             plt.figure(figsize=(10, 10))\n",
    "#             plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "#             plt.axis('off')\n",
    "#             plt.title(f'moving objcs - frame number={frame_number}')\n",
    "#             file_name = f'moving_objcs_{frame_number}.png'\n",
    "#             plt.savefig(video_result_dir_path + file_name)\n",
    "#             plt.show()   \n",
    "    \n",
    "        \n",
    "        \n",
    "#     #-- zip results --\n",
    "#     shutil.make_archive(out_path+video_result_dir_name, 'zip', video_result_dir_path)    \n",
    "\n",
    "#     #-- release videos --\n",
    "#     video.release()\n",
    "#     result_video.release()    \n",
    "    \n",
    "#     print(time_obj)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# #-- remove folders --\n",
    "# shutil.rmtree(result_video_dir)\n",
    "# # display.clear_output()   \n",
    "# print(':)')\n",
    "# #-----------------------------------------------------------------------------------------------------------------    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5033548,
     "sourceId": 8447267,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5262134,
     "sourceId": 8758731,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5276935,
     "sourceId": 8779403,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 114.426671,
   "end_time": "2024-07-09T06:46:19.261372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T06:44:24.834701",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
